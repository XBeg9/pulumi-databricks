# coding=utf-8
# *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import json
import warnings
import pulumi
import pulumi.runtime
from typing import Union
from . import utilities, tables

class Job(pulumi.CustomResource):
    created_time: pulumi.Output[float]
    creator_user_name: pulumi.Output[str]
    email_notifications: pulumi.Output[dict]
    existing_cluster_id: pulumi.Output[str]
    jar_main_class_name: pulumi.Output[str]
    jar_parameters: pulumi.Output[list]
    jar_uri: pulumi.Output[str]
    job_id: pulumi.Output[float]
    library_crans: pulumi.Output[list]
    library_eggs: pulumi.Output[list]
    library_jars: pulumi.Output[list]
    library_mavens: pulumi.Output[list]
    library_pypis: pulumi.Output[list]
    library_whls: pulumi.Output[list]
    max_concurrent_runs: pulumi.Output[float]
    max_retries: pulumi.Output[float]
    min_retry_interval_millis: pulumi.Output[float]
    name: pulumi.Output[str]
    new_cluster: pulumi.Output[dict]
    notebook_base_parameters: pulumi.Output[dict]
    notebook_path: pulumi.Output[str]
    python_file: pulumi.Output[str]
    python_parameters: pulumi.Output[list]
    retry_on_timeout: pulumi.Output[bool]
    schedule: pulumi.Output[dict]
    spark_submit_parameters: pulumi.Output[list]
    timeout_seconds: pulumi.Output[float]
    def __init__(__self__, resource_name, opts=None, email_notifications=None, existing_cluster_id=None, jar_main_class_name=None, jar_parameters=None, jar_uri=None, library_crans=None, library_eggs=None, library_jars=None, library_mavens=None, library_pypis=None, library_whls=None, max_concurrent_runs=None, max_retries=None, min_retry_interval_millis=None, name=None, new_cluster=None, notebook_base_parameters=None, notebook_path=None, python_file=None, python_parameters=None, retry_on_timeout=None, schedule=None, spark_submit_parameters=None, timeout_seconds=None, __props__=None, __name__=None, __opts__=None):
        """
        Create a Job resource with the given unique name, props, and options.
        :param str resource_name: The name of the resource.
        :param pulumi.ResourceOptions opts: Options for the resource.

        The **email_notifications** object supports the following:

          * `noAlertForSkippedRuns` (`pulumi.Input[bool]`)
          * `onFailures` (`pulumi.Input[list]`)
          * `onStarts` (`pulumi.Input[list]`)
          * `onSuccesses` (`pulumi.Input[list]`)

        The **library_crans** object supports the following:

          * `package` (`pulumi.Input[str]`)
          * `repo` (`pulumi.Input[str]`)

        The **library_mavens** object supports the following:

          * `coordinates` (`pulumi.Input[str]`)
          * `exclusions` (`pulumi.Input[list]`)
          * `repo` (`pulumi.Input[str]`)

        The **library_pypis** object supports the following:

          * `package` (`pulumi.Input[str]`)
          * `repo` (`pulumi.Input[str]`)

        The **new_cluster** object supports the following:

          * `autoscale` (`pulumi.Input[dict]`)
            * `maxWorkers` (`pulumi.Input[float]`)
            * `minWorkers` (`pulumi.Input[float]`)

          * `autotermination_minutes` (`pulumi.Input[float]`)
          * `aws_attributes` (`pulumi.Input[dict]`)
            * `availability` (`pulumi.Input[str]`)
            * `ebsVolumeCount` (`pulumi.Input[float]`)
            * `ebsVolumeSize` (`pulumi.Input[float]`)
            * `ebsVolumeType` (`pulumi.Input[str]`)
            * `firstOnDemand` (`pulumi.Input[float]`)
            * `instance_profile_arn` (`pulumi.Input[str]`)
            * `spotBidPricePercent` (`pulumi.Input[float]`)
            * `zoneId` (`pulumi.Input[str]`)

          * `cluster_log_conf` (`pulumi.Input[dict]`)
            * `dbfs` (`pulumi.Input[dict]`)
              * `destination` (`pulumi.Input[str]`)

            * `s3` (`pulumi.Input[dict]`)
              * `cannedAcl` (`pulumi.Input[str]`)
              * `destination` (`pulumi.Input[str]`)
              * `enableEncryption` (`pulumi.Input[bool]`)
              * `encryptionType` (`pulumi.Input[str]`)
              * `endpoint` (`pulumi.Input[str]`)
              * `kmsKey` (`pulumi.Input[str]`)
              * `region` (`pulumi.Input[str]`)

          * `cluster_name` (`pulumi.Input[str]`)
          * `custom_tags` (`pulumi.Input[dict]`)
          * `docker_image` (`pulumi.Input[dict]`)
            * `basicAuth` (`pulumi.Input[dict]`)
              * `password` (`pulumi.Input[str]`)
              * `username` (`pulumi.Input[str]`)

            * `url` (`pulumi.Input[str]`)

          * `driver_node_type_id` (`pulumi.Input[str]`)
          * `enable_elastic_disk` (`pulumi.Input[bool]`)
          * `init_scripts` (`pulumi.Input[list]`)
            * `dbfs` (`pulumi.Input[dict]`)
              * `destination` (`pulumi.Input[str]`)

            * `s3` (`pulumi.Input[dict]`)
              * `cannedAcl` (`pulumi.Input[str]`)
              * `destination` (`pulumi.Input[str]`)
              * `enableEncryption` (`pulumi.Input[bool]`)
              * `encryptionType` (`pulumi.Input[str]`)
              * `endpoint` (`pulumi.Input[str]`)
              * `kmsKey` (`pulumi.Input[str]`)
              * `region` (`pulumi.Input[str]`)

          * `instance_pool_id` (`pulumi.Input[str]`)
          * `node_type_id` (`pulumi.Input[str]`)
          * `num_workers` (`pulumi.Input[float]`)
          * `spark_conf` (`pulumi.Input[dict]`)
          * `spark_env_vars` (`pulumi.Input[dict]`)
          * `spark_version` (`pulumi.Input[str]`)
          * `ssh_public_keys` (`pulumi.Input[list]`)

        The **schedule** object supports the following:

          * `quartzCronExpression` (`pulumi.Input[str]`)
          * `timezoneId` (`pulumi.Input[str]`)
        """
        if __name__ is not None:
            warnings.warn("explicit use of __name__ is deprecated", DeprecationWarning)
            resource_name = __name__
        if __opts__ is not None:
            warnings.warn("explicit use of __opts__ is deprecated, use 'opts' instead", DeprecationWarning)
            opts = __opts__
        if opts is None:
            opts = pulumi.ResourceOptions()
        if not isinstance(opts, pulumi.ResourceOptions):
            raise TypeError('Expected resource options to be a ResourceOptions instance')
        if opts.version is None:
            opts.version = utilities.get_version()
        if opts.id is None:
            if __props__ is not None:
                raise TypeError('__props__ is only valid when passed in combination with a valid opts.id to get an existing resource')
            __props__ = dict()

            __props__['email_notifications'] = email_notifications
            __props__['existing_cluster_id'] = existing_cluster_id
            __props__['jar_main_class_name'] = jar_main_class_name
            __props__['jar_parameters'] = jar_parameters
            __props__['jar_uri'] = jar_uri
            __props__['library_crans'] = library_crans
            __props__['library_eggs'] = library_eggs
            __props__['library_jars'] = library_jars
            __props__['library_mavens'] = library_mavens
            __props__['library_pypis'] = library_pypis
            __props__['library_whls'] = library_whls
            __props__['max_concurrent_runs'] = max_concurrent_runs
            __props__['max_retries'] = max_retries
            __props__['min_retry_interval_millis'] = min_retry_interval_millis
            __props__['name'] = name
            __props__['new_cluster'] = new_cluster
            __props__['notebook_base_parameters'] = notebook_base_parameters
            __props__['notebook_path'] = notebook_path
            __props__['python_file'] = python_file
            __props__['python_parameters'] = python_parameters
            __props__['retry_on_timeout'] = retry_on_timeout
            __props__['schedule'] = schedule
            __props__['spark_submit_parameters'] = spark_submit_parameters
            __props__['timeout_seconds'] = timeout_seconds
            __props__['created_time'] = None
            __props__['creator_user_name'] = None
            __props__['job_id'] = None
        super(Job, __self__).__init__(
            'databricks:index/job:Job',
            resource_name,
            __props__,
            opts)

    @staticmethod
    def get(resource_name, id, opts=None, created_time=None, creator_user_name=None, email_notifications=None, existing_cluster_id=None, jar_main_class_name=None, jar_parameters=None, jar_uri=None, job_id=None, library_crans=None, library_eggs=None, library_jars=None, library_mavens=None, library_pypis=None, library_whls=None, max_concurrent_runs=None, max_retries=None, min_retry_interval_millis=None, name=None, new_cluster=None, notebook_base_parameters=None, notebook_path=None, python_file=None, python_parameters=None, retry_on_timeout=None, schedule=None, spark_submit_parameters=None, timeout_seconds=None):
        """
        Get an existing Job resource's state with the given name, id, and optional extra
        properties used to qualify the lookup.

        :param str resource_name: The unique name of the resulting resource.
        :param str id: The unique provider ID of the resource to lookup.
        :param pulumi.ResourceOptions opts: Options for the resource.

        The **email_notifications** object supports the following:

          * `noAlertForSkippedRuns` (`pulumi.Input[bool]`)
          * `onFailures` (`pulumi.Input[list]`)
          * `onStarts` (`pulumi.Input[list]`)
          * `onSuccesses` (`pulumi.Input[list]`)

        The **library_crans** object supports the following:

          * `package` (`pulumi.Input[str]`)
          * `repo` (`pulumi.Input[str]`)

        The **library_mavens** object supports the following:

          * `coordinates` (`pulumi.Input[str]`)
          * `exclusions` (`pulumi.Input[list]`)
          * `repo` (`pulumi.Input[str]`)

        The **library_pypis** object supports the following:

          * `package` (`pulumi.Input[str]`)
          * `repo` (`pulumi.Input[str]`)

        The **new_cluster** object supports the following:

          * `autoscale` (`pulumi.Input[dict]`)
            * `maxWorkers` (`pulumi.Input[float]`)
            * `minWorkers` (`pulumi.Input[float]`)

          * `autotermination_minutes` (`pulumi.Input[float]`)
          * `aws_attributes` (`pulumi.Input[dict]`)
            * `availability` (`pulumi.Input[str]`)
            * `ebsVolumeCount` (`pulumi.Input[float]`)
            * `ebsVolumeSize` (`pulumi.Input[float]`)
            * `ebsVolumeType` (`pulumi.Input[str]`)
            * `firstOnDemand` (`pulumi.Input[float]`)
            * `instance_profile_arn` (`pulumi.Input[str]`)
            * `spotBidPricePercent` (`pulumi.Input[float]`)
            * `zoneId` (`pulumi.Input[str]`)

          * `cluster_log_conf` (`pulumi.Input[dict]`)
            * `dbfs` (`pulumi.Input[dict]`)
              * `destination` (`pulumi.Input[str]`)

            * `s3` (`pulumi.Input[dict]`)
              * `cannedAcl` (`pulumi.Input[str]`)
              * `destination` (`pulumi.Input[str]`)
              * `enableEncryption` (`pulumi.Input[bool]`)
              * `encryptionType` (`pulumi.Input[str]`)
              * `endpoint` (`pulumi.Input[str]`)
              * `kmsKey` (`pulumi.Input[str]`)
              * `region` (`pulumi.Input[str]`)

          * `cluster_name` (`pulumi.Input[str]`)
          * `custom_tags` (`pulumi.Input[dict]`)
          * `docker_image` (`pulumi.Input[dict]`)
            * `basicAuth` (`pulumi.Input[dict]`)
              * `password` (`pulumi.Input[str]`)
              * `username` (`pulumi.Input[str]`)

            * `url` (`pulumi.Input[str]`)

          * `driver_node_type_id` (`pulumi.Input[str]`)
          * `enable_elastic_disk` (`pulumi.Input[bool]`)
          * `init_scripts` (`pulumi.Input[list]`)
            * `dbfs` (`pulumi.Input[dict]`)
              * `destination` (`pulumi.Input[str]`)

            * `s3` (`pulumi.Input[dict]`)
              * `cannedAcl` (`pulumi.Input[str]`)
              * `destination` (`pulumi.Input[str]`)
              * `enableEncryption` (`pulumi.Input[bool]`)
              * `encryptionType` (`pulumi.Input[str]`)
              * `endpoint` (`pulumi.Input[str]`)
              * `kmsKey` (`pulumi.Input[str]`)
              * `region` (`pulumi.Input[str]`)

          * `instance_pool_id` (`pulumi.Input[str]`)
          * `node_type_id` (`pulumi.Input[str]`)
          * `num_workers` (`pulumi.Input[float]`)
          * `spark_conf` (`pulumi.Input[dict]`)
          * `spark_env_vars` (`pulumi.Input[dict]`)
          * `spark_version` (`pulumi.Input[str]`)
          * `ssh_public_keys` (`pulumi.Input[list]`)

        The **schedule** object supports the following:

          * `quartzCronExpression` (`pulumi.Input[str]`)
          * `timezoneId` (`pulumi.Input[str]`)
        """
        opts = pulumi.ResourceOptions.merge(opts, pulumi.ResourceOptions(id=id))

        __props__ = dict()

        __props__["created_time"] = created_time
        __props__["creator_user_name"] = creator_user_name
        __props__["email_notifications"] = email_notifications
        __props__["existing_cluster_id"] = existing_cluster_id
        __props__["jar_main_class_name"] = jar_main_class_name
        __props__["jar_parameters"] = jar_parameters
        __props__["jar_uri"] = jar_uri
        __props__["job_id"] = job_id
        __props__["library_crans"] = library_crans
        __props__["library_eggs"] = library_eggs
        __props__["library_jars"] = library_jars
        __props__["library_mavens"] = library_mavens
        __props__["library_pypis"] = library_pypis
        __props__["library_whls"] = library_whls
        __props__["max_concurrent_runs"] = max_concurrent_runs
        __props__["max_retries"] = max_retries
        __props__["min_retry_interval_millis"] = min_retry_interval_millis
        __props__["name"] = name
        __props__["new_cluster"] = new_cluster
        __props__["notebook_base_parameters"] = notebook_base_parameters
        __props__["notebook_path"] = notebook_path
        __props__["python_file"] = python_file
        __props__["python_parameters"] = python_parameters
        __props__["retry_on_timeout"] = retry_on_timeout
        __props__["schedule"] = schedule
        __props__["spark_submit_parameters"] = spark_submit_parameters
        __props__["timeout_seconds"] = timeout_seconds
        return Job(resource_name, opts=opts, __props__=__props__)
    def translate_output_property(self, prop):
        return tables._CAMEL_TO_SNAKE_CASE_TABLE.get(prop) or prop

    def translate_input_property(self, prop):
        return tables._SNAKE_TO_CAMEL_CASE_TABLE.get(prop) or prop

